{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7379779,"sourceType":"datasetVersion","datasetId":4288635}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip uninstall -qqy jupyterlab  # Remove unused conflicting packages\n!pip install -U -q \"google-genai==1.7.0\"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-20T18:50:16.928135Z","iopub.execute_input":"2025-04-20T18:50:16.928492Z","iopub.status.idle":"2025-04-20T18:50:22.511721Z","shell.execute_reply.started":"2025-04-20T18:50:16.928462Z","shell.execute_reply":"2025-04-20T18:50:22.510171Z"}},"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Skipping jupyterlab as it is not installed.\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}],"execution_count":75},{"cell_type":"code","source":"from google import genai\nfrom google.genai import types\n\ngenai.__version__","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T18:50:22.514119Z","iopub.execute_input":"2025-04-20T18:50:22.514451Z","iopub.status.idle":"2025-04-20T18:50:22.522820Z","shell.execute_reply.started":"2025-04-20T18:50:22.514397Z","shell.execute_reply":"2025-04-20T18:50:22.521783Z"}},"outputs":[{"execution_count":76,"output_type":"execute_result","data":{"text/plain":"'1.7.0'"},"metadata":{}}],"execution_count":76},{"cell_type":"code","source":"import os, json, uuid, time\nimport pandas as pd\nfrom tqdm import tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T18:50:22.523805Z","iopub.execute_input":"2025-04-20T18:50:22.524042Z","iopub.status.idle":"2025-04-20T18:50:22.540144Z","shell.execute_reply.started":"2025-04-20T18:50:22.524025Z","shell.execute_reply":"2025-04-20T18:50:22.539324Z"}},"outputs":[],"execution_count":77},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\ngcp_key = user_secrets.get_secret(\"gcp_credentials\")\nGOOGLE_API_KEY = user_secrets.get_secret(\"GOOGLE_API_KEY\")\nclient = genai.Client(api_key=GOOGLE_API_KEY)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T18:50:22.542766Z","iopub.execute_input":"2025-04-20T18:50:22.543127Z","iopub.status.idle":"2025-04-20T18:50:22.897397Z","shell.execute_reply.started":"2025-04-20T18:50:22.543097Z","shell.execute_reply":"2025-04-20T18:50:22.896475Z"}},"outputs":[],"execution_count":78},{"cell_type":"code","source":"for model in client.models.list():\n    if \"createTunedModel\" in model.supported_actions:\n        print(model.name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T18:50:22.919998Z","iopub.execute_input":"2025-04-20T18:50:22.920344Z","iopub.status.idle":"2025-04-20T18:50:23.908395Z","shell.execute_reply.started":"2025-04-20T18:50:22.920312Z","shell.execute_reply":"2025-04-20T18:50:23.907492Z"}},"outputs":[{"name":"stdout","text":"models/gemini-1.5-flash-001-tuning\n","output_type":"stream"}],"execution_count":79},{"cell_type":"code","source":"with open(\"/tmp/gcp_key.json\", \"w\") as f:\n    f.write(gcp_key)\n\nos.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/tmp/gcp_key.json\"\n\n# Set your GCP project and region\nPROJECT_ID = \"ai-detection-457406\"\nREGION = \"us-central1\"\nos.environ[\"GOOGLE_CLOUD_PROJECT\"] = PROJECT_ID\n\nfrom google.cloud import aiplatform\nfrom google.cloud import storage","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T18:50:23.911597Z","iopub.execute_input":"2025-04-20T18:50:23.911889Z","iopub.status.idle":"2025-04-20T18:50:23.961939Z","shell.execute_reply.started":"2025-04-20T18:50:23.911871Z","shell.execute_reply":"2025-04-20T18:50:23.960909Z"}},"outputs":[],"execution_count":80},{"cell_type":"code","source":"import pandas as pd\n\n# Load your dataset\ndf = pd.read_csv(\"/kaggle/input/ai-vs-human-text/AI_Human.csv\")\ndf.head()\n# Normalize column names\ndf.columns = [col.strip().lower() for col in df.columns]\n\n# Convert label to readable format\ndf[\"generated\"] = df[\"generated\"].apply(lambda x: \"ai\" if x == 1.0 else \"human\")\ndf[\"text\"] = df[\"text\"].astype(str).str.strip()\ndf = df[[\"text\", \"generated\"]]\n\n\n# Estimate max samples per class (≈ 35%)\nai_count = df[df[\"generated\"] == \"ai\"].shape[0]\nhuman_count = df[df[\"generated\"] == \"human\"].shape[0]\ntarget_total = int(0.35 * (ai_count + human_count))\ntarget_per_class = target_total // 2\n\nprint(f\"Target per class: {target_per_class} samples\")\n\n# Sample balanced set\ndf_sampled = (\n    df.groupby(\"generated\")\n    .apply(lambda x: x.sample(min(len(x), target_per_class), random_state=42))\n    .reset_index(drop=True)\n)\n\nprint(f\"✅ Final sample size: {len(df_sampled)} rows\")\ndf[\"generated\"].value_counts()\ndf_sampled[\"generated\"].value_counts()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T18:50:23.966621Z","iopub.execute_input":"2025-04-20T18:50:23.966889Z","iopub.status.idle":"2025-04-20T18:50:43.161311Z","shell.execute_reply.started":"2025-04-20T18:50:23.966868Z","shell.execute_reply":"2025-04-20T18:50:43.160481Z"}},"outputs":[{"name":"stdout","text":"Target per class: 85266 samples\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_31/1421015253.py:26: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n  .apply(lambda x: x.sample(min(len(x), target_per_class), random_state=42))\n","output_type":"stream"},{"name":"stdout","text":"✅ Final sample size: 170532 rows\n","output_type":"stream"},{"execution_count":81,"output_type":"execute_result","data":{"text/plain":"generated\nai       85266\nhuman    85266\nName: count, dtype: int64"},"metadata":{}}],"execution_count":81},{"cell_type":"code","source":"import pandas as pd\n\n# 1. See which labels appear\nprint(df['generated'].value_counts())\n# e.g. \n# human    1200\n# ai         45\n# Name: generated, dtype: int64\n\n# 2. Check whether any “ai” rows exist\nhas_ai = df['generated'].eq('ai').any()\nprint(\"Any AI‑generated text?\", has_ai)\n\n# 3. How many?\nai_count = df['generated'].eq('ai').sum()\nprint(f\"Found {ai_count} AI‑generated examples out of {len(df)} total.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T18:50:43.162472Z","iopub.execute_input":"2025-04-20T18:50:43.162898Z","iopub.status.idle":"2025-04-20T18:50:43.330228Z","shell.execute_reply.started":"2025-04-20T18:50:43.162866Z","shell.execute_reply":"2025-04-20T18:50:43.329222Z"}},"outputs":[{"name":"stdout","text":"generated\nhuman    305797\nai       181438\nName: count, dtype: int64\nAny AI‑generated text? True\nFound 181438 AI‑generated examples out of 487235 total.\n","output_type":"stream"}],"execution_count":82},{"cell_type":"code","source":"df_sampled[\"generated\"].unique()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T18:50:43.331131Z","iopub.execute_input":"2025-04-20T18:50:43.331375Z","iopub.status.idle":"2025-04-20T18:50:43.360599Z","shell.execute_reply.started":"2025-04-20T18:50:43.331356Z","shell.execute_reply":"2025-04-20T18:50:43.359497Z"}},"outputs":[{"execution_count":83,"output_type":"execute_result","data":{"text/plain":"array(['ai', 'human'], dtype=object)"},"metadata":{}}],"execution_count":83},{"cell_type":"code","source":"ai_rows = df_sampled[df_sampled.get(\"generated\") == \"ai\"]\nif ai_rows.empty:\n    print(\"No AI-generated rows found in your dataset.\")\nelse:\n    # 2b.1: Sample a random AI-generated row\n    random_ai_row = ai_rows.sample(n=1).iloc[0]\n    print(\"Random AI-generated row:\\n\", random_ai_row)\n\n    # 2b.2: Retrieve a specific AI-generated row by position\n    row_index = 0  # change index as needed (0-based)\n    specific_ai_row = ai_rows.iloc[row_index]\n    print(f\"\\nAI-generated row at position {row_index}:\\n\", specific_ai_row)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T18:50:43.382772Z","iopub.execute_input":"2025-04-20T18:50:43.383070Z","iopub.status.idle":"2025-04-20T18:50:43.413646Z","shell.execute_reply.started":"2025-04-20T18:50:43.383052Z","shell.execute_reply":"2025-04-20T18:50:43.412667Z"}},"outputs":[{"name":"stdout","text":"Random AI-generated row:\n text         Title: Car-Free Cities: The Future or a Fantas...\ngenerated                                                   ai\nName: 23142, dtype: object\n\nAI-generated row at position 0:\n text         I believe that online classes and video confer...\ngenerated                                                   ai\nName: 0, dtype: object\n","output_type":"stream"}],"execution_count":84},{"cell_type":"code","source":"from collections.abc import Iterable\nimport random\n\nimport random\n\nmax_epochs = 1\nmax_steps = 250_000\nmax_examples = max_steps // max_epochs\n\ntuning_examples = [\n    types.TuningExample(\n        text_input=row[\"text\"],\n        output=(\n            \"This text was generated by AI.\"\n            if row[\"generated\"] == \"ai\"\n            else \"This text was written by a human.\"\n        )\n    )\n    for _, row in df_sampled.iterrows()\n]\n\n# 2. Wrap in a TuningDataset\ntraining_dataset = types.TuningDataset(examples=tuning_examples)\n\n\n\n\n# If you are re-running this lab, add your model_id here.\nmodel_id = None\n\n# Or try and find a recent tuning job.\nif not model_id:\n  queued_model = None\n  # Newest models first.\n  for m in reversed(client.tunings.list()):\n    # Only look at newsgroup classification models.\n    if m.name.startswith('tunedModels/newsgroup-classification-model'):\n      # If there is a completed model, use the first (newest) one.\n      if m.state.name == 'JOB_STATE_SUCCEEDED':\n        model_id = m.name\n        print('Found existing tuned model to reuse.')\n        break\n\n      elif m.state.name == 'JOB_STATE_RUNNING' and not queued_model:\n        # If there's a model still queued, remember the most recent one.\n        queued_model = m.name\n  else:\n    if queued_model:\n      model_id = queued_model\n      print('Found queued model, still waiting.')\n\n\n# Upload the training data and queue the tuning job.\nif not model_id:\n    try:\n        print(\"🚀 Launching tuning job (non-blocking)...\")\n        tuning_op = client.tunings.tune(\n            base_model=\"models/gemini-1.5-flash-001\",\n            training_dataset=training_dataset,\n            config=types.CreateTuningJobConfig(\n                tuned_model_display_name=f\"ai-detector-{int(time.time())}\",\n                batch_size=4,\n                epoch_count=1,\n            ),\n        )\n        model_id = tuning_op.name\n        print(f\"✅ Job launched! Model ID: {model_id}\")\n    except Exception as e:\n        print(\"❌ Failed to launch tuning job:\")\n        print(e)\n\nprint(model_id)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T18:54:44.145856Z","iopub.execute_input":"2025-04-20T18:54:44.146290Z","iopub.status.idle":"2025-04-20T18:55:06.048686Z","shell.execute_reply.started":"2025-04-20T18:54:44.146265Z","shell.execute_reply":"2025-04-20T18:55:06.047795Z"}},"outputs":[{"name":"stdout","text":"🚀 Launching tuning job (non-blocking)...\n❌ Failed to launch tuning job:\n400 FAILED_PRECONDITION. {'error': {'code': 400, 'message': 'models/gemini-1.5-flash-001 is not found for CREATE TUNED MODEL at API version v1beta.', 'status': 'FAILED_PRECONDITION'}}\nNone\n","output_type":"stream"}],"execution_count":91},{"cell_type":"code","source":"for job in client.tunings.list(config={'page_size': 50}):\n    print(job.name, job.state.name, job.tuned_model.model if job.tuned_model else None)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T18:52:37.472242Z","iopub.execute_input":"2025-04-20T18:52:37.472875Z","iopub.status.idle":"2025-04-20T18:52:37.840954Z","shell.execute_reply.started":"2025-04-20T18:52:37.472847Z","shell.execute_reply":"2025-04-20T18:52:37.839858Z"}},"outputs":[{"name":"stdout","text":"tunedModels/aidetectormodel-qv7hrundwrke JOB_STATE_SUCCEEDED tunedModels/aidetectormodel-qv7hrundwrke\n","output_type":"stream"}],"execution_count":89},{"cell_type":"code","source":"from google.genai import types\n\njob_name = \"tunedModels/aidetectormodel-qv7hrundwrke\"  # from your client.tunings.tune(...) call\n\n# Fetch its latest status\nstatus = client.tunings.get(name=job_name)\nprint(status.state.name)  # e.g. “JOB_STATE_RUNNING”, then eventually “JOB_STATE_SUCCEEDED”\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T18:51:24.823797Z","iopub.status.idle":"2025-04-20T18:51:24.824083Z","shell.execute_reply.started":"2025-04-20T18:51:24.823947Z","shell.execute_reply":"2025-04-20T18:51:24.823960Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tuned_model_name = status.tuned_model.model\nprint(\"Ready model:\", tuned_model_name)\n# e.g. \"tunedModels/az2mb0bpw6i\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T18:51:24.825010Z","iopub.status.idle":"2025-04-20T18:51:24.825257Z","shell.execute_reply.started":"2025-04-20T18:51:24.825142Z","shell.execute_reply":"2025-04-20T18:51:24.825153Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"response = client.models.generate_content(\n    model=tuned_model_name,\n    contents='''genertaed by ai: Cars are one of the major contributors to environmental pollution, releasing harmful emissions that significantly impact air quality and contribute to climate change. The combustion of fossil fuels in car engines produces pollutants such as carbon dioxide (CO2), nitrogen oxides (NOx), particulate matter, and volatile organic compounds (VOCs). CO2, a greenhouse gas, is the primary driver of global warming, while NOx and particulate matter can cause respiratory issues and other health problems. Additionally, the production and disposal of vehicles generate waste and consume vast amounts of resources. The growing adoption of electric vehicles and advancements in clean energy technologies are essential steps toward reducing the environmental footprint of transportation and protecting our planet for future generations.''',\n)\nprint(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T18:51:24.826134Z","iopub.status.idle":"2025-04-20T18:51:24.826395Z","shell.execute_reply.started":"2025-04-20T18:51:24.826268Z","shell.execute_reply":"2025-04-20T18:51:24.826279Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}